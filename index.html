<!DOCTYPE HTML>
<html lang="en">
<head>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  <title>Jeong-gi Kwak</title>
  <meta name="author" content="Jeong-gi Kwak">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <link rel="shortcut icon" href="images/favicon/favicon.ico" type="image/x-icon">
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
  <!-- Font Awesome for icons -->
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.0/css/all.min.css">
</head>

<body>
    <table style="width:100%;max-width:800px;margin:auto;border-spacing:0;">
        <tr>
          <td style="padding:2.5%;width:63%;vertical-align:middle">
            <p class="name" style="text-align:center;">Jeong-gi Kwak</p>
            <p>
              I'm a research scientist at <a href="https://nxn.ai/">NXN Labs</a>, 
              where I'm developing large-scale generative foundation models for fashion imagery. <br>
              My research interest lies in image/video generation and 3D computer vision, 
              with the broader goal of modeling and interacting with the visual world. 
              Prior to NXN Labs, I was at Innerverz AI, focusing on video diffusion models. 
              I earned my PhD from Korea University, advised by Prof. Hanseok Ko. 
              I also completed my B.S and M.S degrees in Electrical Engineering from Korea University.
            </p>
            <p style="text-align:center">
              <a href="https://scholar.google.co.kr/citations?user=OokxUB4AAAAJ">Google Scholar</a> &nbsp;/&nbsp;
              <a href="https://github.com/jgkwak95">Github</a> &nbsp;/&nbsp;
              <a href="data/CV_jgkwak.pdf">CV</a> &nbsp;/&nbsp;
              <a href="mailto:kjk8557@korea.ac.kr">Email</a> &nbsp;/&nbsp;
              <a href="https://www.linkedin.com/in/jeong-gi-kwak-743668203/">Linkedin</a>
            </p>
          </td>
      
          <td style="padding:2.5%;width:37%;vertical-align:middle;">
            <img src="images/profile.jpg" style="width:85%;">
          </td>
        </tr>
      </table>

<!-- News -->
<table style="width:100%;max-width:800px;margin:auto;border-spacing:0;">
    <tr>
      <td style="padding:0px">
        <h2>News</h2>
        <ul>
          <li><b>Jul. 2025:</b> In September, I will start a postdoctoral fellow position at the University of British Columbia (UBC), working with Prof. <a href="https://www.cs.ubc.ca/~kmyi/">Kwang Moo Yi</a>.</li>
          <li><b>Jun. 2025:</b> Recognized as an <a href="https://cvpr.thecvf.com/Conferences/2025/ProgramCommittee#all-outstanding-reviewer">Outstanding Reviewer</a> at CVPR 2025 (711/12,593 reviewers).</li>
          <li><b>May 2025:</b> One paper has been accepted to CVPRW 2025.</li>
          <li><b>Dec. 2024:</b> I’ve joined <a href="https://nxn.ai/">NXN Labs</a> as an AI researcher, focusing on visual generative/editing models.</li>
          <li><b>Jul. 2024:</b> I will be giving a talk at <a href="https://www.twelvelabs.io/">Twelve Labs</a>.</li>
          <li><b>Apr. 2024:</b> Our paper has been selected as one of <a href="https://public.tableau.com/views/CVPR2024/CVPRtrends?:showVizHome=no">Highlight Papers</a> at CVPR 2024 (Top 10%).</li>
          <li><b>Feb. 2024:</b> One paper has been accepted to <a href="https://cvpr.thecvf.com">CVPR 2024</a>.</li>
          <li><b>Jan. 2024:</b> One paper has been accepted to <a href="https://2024.ieeeicassp.org/">ICASSP 2024</a>.</li>
          <li><b>Jan. 2024:</b> I've Joined <a href="https://innerverz.io/">Innerverz AI</a> as an AI/ML researcher, focusing on video diffusion models.</li>
          <li><b>Dec. 2023:</b> Successfully defended my thesis, “Towards Controllable and Interpretable Generative Neural Rendering”.</li>
          <li><b>Dec. 2023:</b> Completed a 6-month visit to the University of British Columbia (UBC) as a PhD visiting student in the Computer Vision Lab, supervised by Prof. <a href="https://www.cs.ubc.ca/~kmyi/">Kwang Moo Yi</a>.</li>
        </ul>
      </td>
    </tr>
  </table>

<!-- Publications -->

<table class="publications" style="width:100%;max-width:800px;margin:auto;">
    <tr><td style="padding:12px"><h2>Selected Publications</h2></td></tr>
  </table>
  
  <table class="publications" style="width:100%;max-width:800px;margin:auto;">
      <!-- SA 2025 -->
      <tr class="publication-row">
        <td class="pub-img" style="width:25%;vertical-align:middle">
          <img src="images/voost.png" width="150" height="140">
        </td>
        <td style="width:75%;vertical-align:middle;padding-left:20px;">
          <span class="papertitle">Voost: A Unified and Scalable Diffusion Transformer for Bidirectional Virtual <br>Try-On and Try-Off</span><br>
          <span class="coauthors">Seungyong Lee*</span>, <b>Jeong-gi Kwak*</b><br>
          <em>Arxiv preprint</em>, 2025<br>
          <a href="">paper</a> |
          <a href="">project page</a> |
          <a href="">demo</a>
        </td>
      </tr>

    <!-- ViVid-1-to-3 (CVPR 2024, Highlight) -->
    <tr class="publication-row" onmouseout="vivid_stop()" onmouseover="vivid_start()">
      <td class="pub-img" style="width:25%;vertical-align:middle">
        <div class="one" style="width:110px; height:110px;">
          <div class="two" id="vivid_video">
            <video width="110" height="110" muted autoplay loop>
              <source src="images/rockingchair.mp4" type="video/mp4">
            </video>
          </div>
          <img src="images/rockingchair.png" width="110">
        </div>
      </td>
      <td style="width:75%;vertical-align:middle;padding-left:20px;">
          <span class="papertitle">ViVid-1-to-3: Novel View Synthesis with Video Diffusion Models</span>
        </a><br>
        <b>Jeong-gi Kwak*</b>, <span class="coauthors">Erqun Dong*</span>, <span class="coauthors">Yuhe Jin</span>, <span class="coauthors">Hanseok Ko</span>, <span class="coauthors">Shweta Mahajan</span>, <span class="coauthors">Kwang Moo Yi</span><br>
        <em>IEEE/CVF Conference on Computer Vision and Pattern Recognition (<b>CVPR</b>)</em>, 2024 <br><b class="highlight-note">Highlight (Top 10%)</b><br>
        <a href="https://openaccess.thecvf.com/content/CVPR2024/papers/Kwak_ViVid-1-to-3_Novel_View_Synthesis_with_Video_Diffusion_Models_CVPR_2024_paper.pdf">paper</a> |
        <a href="https://github.com/ubc-vision/vivid123">code</a> |
        <a href="https://jgkwak95.github.io/ViVid-1-to-3/">project page</a>
      </td>
    </tr>
  
    <!-- ICASSP 2024 -->
    <tr class="publication-row">
      <td class="pub-img" style="width:25%;vertical-align:middle">
        <img src="images/Li_icassp.png" width="100" height="70">
      </td>
      <td style="width:75%;vertical-align:middle;padding-left:20px;">
        <span class="papertitle">Towards Multi-domain Face Landmark Detection with Synthetic Data from Diffusion Model</span><br>
        <span class="coauthors">Yuanming Li</span>, <span class="coauthors">Gwantae Kim</span>, <b>Jeong-gi Kwak</b>, <span class="coauthors">Bonhwa Ku</span>, <span class="coauthors">Hanseok Ko</span><br>
        <em>IEEE International Conference on Acoustics, Speech and Signal Processing (<b>ICASSP</b>)</em>, 2024<br>
        <a href="https://arxiv.org/abs/2401.13191">paper</a>
      </td>
    </tr>
  
    <!-- ECCV 2022 -->
    <tr class="publication-row" onmouseout="tom_stop()" onmouseover="tom_start()" style="position:relative; ">
      <td class="pub-img" style="width:25%;vertical-align:middle">
        <div class="one" style="width:160px; height:80px;">
          <div class="two" id="tom_video">
            <video width="160" height="80" muted autoplay loop>
              <source src="images/tom.mp4" type="video/mp4">
            </video>
          </div>
          <img src="images/tom.png" height="80" width="160">
        </div>
      </td>
      <td style="width:75%;vertical-align:middle;padding-left:20px; ">
        <span class="papertitle">
          Injecting 3D Perception of Controllable NeRF-GAN into StyleGAN for Editable Portrait <br>Image Synthesis
        </span><br>
        <b>Jeong-gi Kwak</b>, <span class="coauthors">Yuanming Li</span>, <span class="coauthors">Dongsik Yoon</span>, <span class="coauthors">Donghyeon Kim</span>, <span class="coauthors">David Han</span>, <span class="coauthors">Hanseok Ko</span><br>
        <em>European Conference on Computer Vision (<b>ECCV</b>)</em>, 2022 <br><b class="highlight-note">ETNews ICT Paper Awards sponsored by MSIT Korea</b><br>
        <a href="http://arxiv.org/abs/2207.10257">paper</a> |
        <a href="https://github.com/jgkwak95/SURF-GAN">code</a> |
        <a href="https://jgkwak95.github.io/surfgan/">project page</a>
      </td>
    </tr>
  
    <!-- DIFAI (ICIP 2022) -->
    <tr class="publication-row">
      <td class="pub-img" style="width:25%;vertical-align:middle">
        <img src="images/difai.png" height="70" width="140">
      </td>
      <td style="width:75%;vertical-align:middle;padding-left:20px;">
        <span class="papertitle">DIFAI: Diverse Facial Inpainting using StyleGAN Inversion</span><br>
        <span class="coauthors">Dongsik Yoon</span>, <b>Jeong-gi Kwak</b>, <span class="coauthors">Yuanming Li</span>, <span class="coauthors">David Han</span>, <span class="coauthors">Hanseok Ko</span><br>
        <em>IEEE International Conference on Image Processing (<b>ICIP</b>)</em>, 2022<br>
        <a href="https://ieeexplore.ieee.org/document/9898012">paper</a>
      </td>
    </tr>
  
    <!-- CVPRW 2022 -->
    <tr class="publication-row">
      <td class="pub-img" style="width:25%;vertical-align:middle">
        <img src="images/cvprw_thumb.png" height="70" width="180">
      </td>
      <td style="width:75%;vertical-align:middle;padding-left:20px;">
        <span class="papertitle">Generate and Edit Your Own Character in a Canonical View</span><br>
        <b>Jeong-gi Kwak</b>, <span class="coauthors">Yuanming Li</span>, <span class="coauthors">Dongsik Yoon</span>, <span class="coauthors">David Han</span>, <span class="coauthors">Hanseok Ko</span><br>
        <em>IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (<b>CVPRW</b>)</em>, 2022<br>
        <a href="https://arxiv.org/abs/2205.02974">paper</a> |
        <a href="files/cvpr_poster.pdf">poster</a>
      </td>
    </tr>
  
    <!-- BMVC 2021 Adverse Weather -->
    <tr class="publication-row">
      <td class="pub-img" style="width:25%;vertical-align:middle">
        <img src="images/augan.png" height="70" width="180">
      </td>
      <td style="width:75%;vertical-align:middle;padding-left:20px;">
        <span class="papertitle">Adverse Weather Image Translation with Asymmetric and Uncertainty-aware GAN</span><br>
        <b>Jeong-gi Kwak</b>, <span class="coauthors">Youngsaeng Jin</span>, <span class="coauthors">Yuanming Li</span>, <span class="coauthors">Dongsik Yoon</span>, <span class="coauthors">Donghyeon Kim</span>, <span class="coauthors">Hanseok Ko</span><br>
        <em>British Machine Vision Conference (<b>BMVC</b>)</em>, 2021<br>
        <a href="https://www.bmvc2021-virtualconference.com/assets/papers/1443.pdf">paper</a> |
        <a href="https://github.com/jgkwak95/AU-GAN">code</a>
      </td>
    </tr>
  
    <!-- BMVC 2021 Reference Guided -->
    <tr class="publication-row">
      <td class="pub-img" style="width:25%;vertical-align:middle">
        <img src="images/yoon_bmvc.png" height="70" width="180">
      </td>
      <td style="width:75%;vertical-align:middle;padding-left:20px;">
        <span class="papertitle">Reference Guided Image Inpainting using Facial Attributes</span><br>
        <span class="coauthors">Dongsik Yoon</span>, <b>Jeong-gi Kwak</b>, <span class="coauthors">Yuanming Li</span>, <span class="coauthors">David Han</span>, <span class="coauthors">Youngsaeng Jin</span>, <span class="coauthors">Hanseok Ko</span><br>
        <em>British Machine Vision Conference (<b>BMVC</b>)</em>, 2021<br>
        <a href="https://www.bmvc2021-virtualconference.com/assets/papers/1267.pdf">paper</a> |
        <a href="https://github.com/Stillrot/RGINP">code</a>
      </td>
    </tr>
  
    <!-- ECCV 2020 -->
    <tr class="publication-row">
      <td class="pub-img" style="width:25%;vertical-align:middle">
        <img src="images/cafegan.png" height="70" width="140">
      </td>
      <td style="width:75%;vertical-align:middle;padding-left:20px;">
        <span class="papertitle">CAFE-GAN: Arbitrary Face Attribute Editing with Complementary Attention Feature</span><br>
        <b>Jeong-gi Kwak</b>, <span class="coauthors">David K. Han</span>, <span class="coauthors">Hanseok Ko</span><br>
        <em>European Conference on Computer Vision (<b>ECCV</b>)</em>, 2020<br>
        <a href="https://arxiv.org/pdf/2011.11900.pdf">paper</a>
      </td>
    </tr>
  </table>
  
  <script>
    function vivid_start() { document.getElementById('vivid_video').style.opacity = "1"; }
    function vivid_stop()  { document.getElementById('vivid_video').style.opacity = "0"; }
    function tom_start()   { document.getElementById('tom_video').style.opacity = "1"; }
    function tom_stop()    { document.getElementById('tom_video').style.opacity = "0"; }
  
    document.addEventListener('DOMContentLoaded', function() {
      vivid_stop();
      tom_stop();
    });
  </script>
  
  <style>
    .coauthors {
      color: #555;
    }
  </style>
  

<!-- Academic Service -->
<table style="width:100%;max-width:800px;margin:auto;border-spacing:0; margin-top:30px;">
    <tr><td style="padding:12px"><h2>Academic Service</h2></td></tr>
  </table>
  
  <table style="width:100%;max-width:800px;margin:auto;">
    <tr>
      <td style="padding:4px 0;">
        Reviewer for international conferences and journals:
        <ul style="margin:4px 0 0 20px; padding:0;">
          <li>CVPR (2025, 2024, 2022)</li>
          <li>NeurIPS (2025, 2023)</li>
          <li>AAAI (2025)</li>
          <li>SIGGRAPH Asia (2025)</li>
          <li>WACV (2026)</li>
          <li>ECCV (2022)</li>
          <li>ICASSP (2023, 2022, 2021)</li>
          <li>CVIU (2023)</li>
        </ul>
      </td>
    </tr>
  </table>


<!-- Footer -->
<table style="width:100%;max-width:800px;margin:auto; margin-top:80px; border-spacing:0;">
    <tr>
      <td style="text-align:center; font-size:12px; color:#aaa;">
        This website template is adapted from 
        <a href="https://jonbarron.info/" style="color:#aaa; text-decoration:none;">
          Jon Barron's homepage
        </a>.
      </td>
    </tr>
  </table>