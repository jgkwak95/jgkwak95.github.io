<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="Injecting 3D Perception of Controllable NeRF-GAN into StyleGAN for Editable Portrait Image Synthesis">
  <meta name="keywords" content="SURF-GAN, 3D-controllable StyleGAN">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>SURF-GAN</title>

  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-ZPG4LM1L01"></script>
  <script>
    window.dataLayer = window.dataLayer || [];

    function gtag() {
      dataLayer.push(arguments);
    }

    gtag('js', new Date());

    gtag('config', 'G-ZPG4LM1L01');
  </script>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="icon" href="./static/images/favicon.svg">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
</head>
<body>


<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-2 publication-title"> Injecting 3D Perception of Controllable NeRF-GAN into StyleGAN for Editable Portrait Image Synthesis </h1>
          <h3 class="title is-4 publication-title"> ECCV 2022 </h3>
          <div class="is-size-5 publication-authors">
            <span class="author-block">
              <a href="https://jgkwak95.github.io/">Jeong-gi Kwak</a><sup>1</sup>,</span>
            <span class="author-block">
              Yuanming Li</a><sup>1</sup>,</span>
            <span class="author-block">
              Dongsik Yoon</a><sup>1</sup>,
            </span>
            <span class="author-block">
              Donghyeon Kim</a><sup>1</sup>,
            </span>
            <span class="author-block">
              David Han</a><sup>2</sup>,
            </span>
            <span class="author-block">
              Hanseok Ko</a><sup>1</sup>,
            </span>
            
          </div>

          <div class="is-size-5 publication-authors">
            <span class="author-block"><sup>1</sup>Korea University,</span>
            <span class="author-block"><sup>2</sup>Drexel University</span>
          </div>

          <div class="column has-text-centered">
            <div class="publication-links">
              <!-- PDF Link. -->
              <span class="link-block">
                <a href="http://arxiv.org/abs/2207.10257"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Paper</span>
                </a>
              </span>

              <!-- Code Link. -->
              <span class="link-block">
                <a href="https://github.com/jgkwak95/SURF-GAN"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code</span>
                  </a>
              </span>

            </div>

          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<div class="columns is-centered has-text-centered">
  <div class="column is-four-fifths">
    <!-- <h3 class="title is-3">Overview</h3> -->

      <img src="./assets/thumb.png"  width="1000" class="center"/>
      <br><br>

      <video id="teaser" autoplay muted loop playsinline width="50%">
        <source src="./assets/vid/son_tom_edit.mp4"
                type="video/mp4" class="center">
      </video>


  </div>
  </div>

<div class="columns is-centered has-text-centered">
  <!-- <div class="container is-max-desktop content"> -->
  <div class="column is-four-fifths"><br>

      <blockquote style="font-size:21px">
        <h4><em>Recently, unconditional GAN models are divided into two main categories. <br>
          <br>
          <b>2D GANs</b> have achieved <b>photorealism</b> and offer diverse options to control <b>semantic attributes</b> in generation or editing.<br>
          However, they lack <b>3D understanding</b> in generation process. Existing editing models allow <b>implicit</b> pose control. <br>

          <br>
          Recently proposed <b>3D-aware GANs</b> have tackled the <b>multi-view consistency</b> problem and achieved (explicit) <b>3D controllability</b>.<br>
          Although they have shown results of style mixing or interpolation, 3D GANs struggle to <b>disentangle</b> and <b>control</b> the <b>semantic attributes</b>.<br>

          

        </em></h4>
      </blockquote>
  </div>
</div>
<br>

  <br>
  <section class="hero teaser">
    <div class="columns is-centered has-text-centered">
    <div class="container is-max-desktop">
      <div class="hero-body">
        <video id="teaser" autoplay muted loop playsinline width="15%">
          <source src="./assets/vid/vid_surfgan.mp4"
                  type="video/mp4" class="center">
        </video>
        <h2 class="subtitle has-text-centered">
          SURF-GAN, which is a NeRF-based 3D-aware GAN, can discover semantic attributes in an  
          unsupervised manner and enables users to control them as well as camera parameters. 
          <p>(Trained on 64x64 CelebA and rendered at 256x256)</p><br>
        </h2>
        <video id="teaser" autoplay muted loop playsinline width="85%">
          <source src="./assets/vid/vid_thumb.mp4"
                  type="video/mp4" class="center">
        </video>
        <img src="./assets/text2.png"  width="70%" class="center"/>
        <h2 class="subtitle has-text-centered">
We inject the prior of SURF-GAN into StyleGAN for explicit pose control and editable directions.  
          
            <p>(Rendered at 1024x1024)</p><br>

        </h2>
      </div>
    </div>
    </div>
  </section>

<section class="section" id="Abstract">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
          Over the years, 2D GANs have achieved great successes in photorealistic portrait generation. However, they lack 3D understanding in the generation process, thus they suffer from multi-view inconsistency problem. To alleviate the issue, many 3D-aware GANs have been proposed and shown notable results, but 3D GANs struggle with editing semantic attributes. The controllability and interpretability of 3D GANs have not been much explored. In this work, we propose two solutions to overcome these weaknesses of 2D GANs and 3D-aware GANs.
We first introduce a novel  3D-aware GAN, SURF-GAN, which is capable of discovering semantic attributes during training and controlling them in an unsupervised manner.
After that, we inject the prior of SURF-GAN into StyleGAN to obtain a high-fidelity 3D-controllable generator.
Unlike existing latent-based methods allowing implicit pose control, the proposed 3D-controllable StyleGAN enables explicit pose control over portrait generation.
This distillation allows direct compatibility between 3D control and  many StyleGAN-based techniques (e.g., inversion and stylization), and also brings an advantage in terms of computational resources.
</p></p><b>TL;DR </b>  We present a novel 3D-aware GAN, i.e., <b>SURF-GAN</b>, which is able to disentangle and control semantic
attributes and then <b>make StyleGAN 3D controllable</b> by injecting the prior of SURF-GAN.
          </p>

        </div>
      </div>
    </div>

  </div>
</section>


<section class="section" id="surf-gan">
  <div class="container is-max-desktop content">
    <h2 class="title">SURF-GAN</h2>
    <p>
      We propose a novel 3D-aware GAN, i.e., SURF-GAN, which can discover semantic attributes by learning layer-wise subspace in INR NeRF-based generator in an unsupervised manner. 
    </p>

  <h4 class="title"> Architecture</h4>
    <img src="assets/surfgan.png"  height="250" class="center"/>
    <p></p>
    <p><h4 class="content">3D-aware generation</h4></p>
    <img src="assets/surf_result1.png"  width="1000" class="center"/>

    <p></p>

    <h4 class="content">Semantic attributes discovered by SURF-GAN</h4>
    <div><img src="assets/surf_result2.png"  width="1000" class="center"/>
    </div>
  </section>

  <section class="section" id="3d-stylegan">
    <div class="container is-max-desktop content">

    <h2 class="title">3D-controllable StyleGAN</h2>
    <p>
      After that, we inject 3D prior from a low-resolution 3D-Aware GAN (SURF-GAN) into a high-resolution 2D GAN (StyleGAN).
    </p>
    <h4 class="title">Control over pose</h4>
    <img src="assets/result1.png"  width="1000" class="center"/>
    <p></p>
    <h4 class="title"> + Stylization</h4>
    <img src="assets/result2.png"  width="1000" class="center"/>
    <p></p>
    <h4 class="title"> + Editing</h4>
    <img src="assets/editing.png"  width="1000" class="center"/>
    <p></p>
  </div>



  <div class="columns is-centered has-text-centered">
  <div class="container is-max-desktop content">
    <div class="hero-body">
      
      <div>
      <h2 class="title"> Video</h2>
      <p>
      <h4 class="subtitle has-text-centered"></p>
        With a canonical mapping, our model can process portrait images in arbitrary poses.
     </h4>

        <div class="container is-max-desktop">
     
          <div class="columns is-centered">
  
            <div class="column">
              <div class="content">
               
                <video id="vid5" autoplay controls muted loop playsinline width="100%">
                  <source src="https://jgkwak95.github.io/surfgan/assets/vid/vid1.mp4"
                          type="video/mp4">
                </video>
              </div>
            </div>

            <div class="column">
              <div class="columns is-centered">
                <div class="column content">
                  <video id="vid6" autoplay controls muted loop playsinline width="100%">
                    <source src="https://jgkwak95.github.io/surfgan/assets/vid/vid2.mp4"
                            type="video/mp4">
                  </video> 
                </div>
      
              </div>
            </div>
          </div>
        </div>

        <div class="container is-max-desktop">
     
          <div class="columns is-centered">
            <div class="column">
              <div class="content">
               
                <video id="vid5" autoplay controls muted loop playsinline width="100%">
                  <source src="https://jgkwak95.github.io/surfgan/assets/vid/vid3.mp4"
                          type="video/mp4">
                </video>
              </div>
            </div>
            <div class="column">
              <div class="columns is-centered">
                <div class="column content">
                  <video id="vid6" autoplay controls muted loop playsinline width="100%">
                    <source src="https://jgkwak95.github.io/surfgan/assets/vid/vid4.mp4"
                            type="video/mp4">
                  </video> 
                </div>
      
              </div>
            </div>
          </div>
        </div>



      <h4 class="subtitle has-text-centered">
        <br>  Also, it is comatible with numerous StyleGAN-based techniques, e.g., Toonifying.
      </h4>
    </div>

    <div class="container is-max-desktop">
     
      <div class="columns is-centered">
  
    
        <div class="column">
          <div class="content">
           
            <video id="vid5" autoplay controls muted loop playsinline width="100%">
              <source src="https://jgkwak95.github.io/surfgan/assets/vid/vid5.mp4"
                      type="video/mp4">
            </video>
          </div>
        </div>

        <div class="column">
          <div class="columns is-centered">
            <div class="column content">
              <video id="vid6" autoplay controls muted loop playsinline width="100%">
                <source src="https://jgkwak95.github.io/surfgan/assets/vid/vid6.mp4"
                        type="video/mp4">
              </video>
            </div>
  
          </div>
        </div>
      </div>
    </div>

<br>

    <h4 class="title is-5"> Editing pose of challenging real images with HyperStyle. </h4>
    <div class="container is-max-desktop">

      <div class="columns is-centered">
  
   
        <div class="column">
          <div class="content">

            <video id="dollyzoom" autoplay controls muted loop playsinline height="100%">
              <source src="assets/vid/son_yaw.mp4"
                      type="video/mp4">
            </video>
          </div>
        </div>

        <div class="column">
          <div class="columns is-centered">
            <div class="column content">
              <video id="dollyzoom" autoplay controls muted loop playsinline height="100%">
                <source src="assets/vid/tangwei_circle.mp4"
                        type="video/mp4">
              </video>
            </div>
  
          </div>
        </div>
      </div>
    </div>
      <div class="container is-max-desktop">
  <br>
    
        
        <h4 class="title is-5"> In addition, we can edit semantic attributes using discovered attribute directions. </h4>
        <div class="columns is-centered">
 
          <div class="column">
            <div class="content">

              <video id="dollyzoom" autoplay controls muted loop playsinline height="100%">
                <source src="assets/vid/tom_circle_smile.mp4"
                        type="video/mp4">
              </video>
              smile (using InterFaceGAN)
            </div>
          </div>
          <div class="column">
            <div class="columns is-centered">
              <div class="column content">
                <video id="dollyzoom" autoplay controls muted loop playsinline height="100%">
                  <source src="assets/vid/curry_pitch_ill.mp4"
                          type="video/mp4">
                </video>
                Illumination (using SURF-GAN samples)
              </div>
    
            </div>
          </div>
        </div>
      </div>


  
    <h2 class="subtitle has-text-centered">
  
      Limitation
   </h2>
   Our 3D controllable StyleGAN is not based on 3D representations such as mesh or NeRF, so as you can see when it comes to video generation, it shows the problem of “texture sticking”  pointed out in <a href="https://nvlabs.github.io/stylegan3/">StyleGAN3</a> (especially in hair and beard).
   That is one of the most noticable artifacts in GAN generated videos. We expect this to be mitigated with StyleGAN3.

  <div class="container is-max-desktop">
     
    <div class="columns is-centered">

      <div class="column">
        <div class="content">
         
          <video id="vid5" autoplay controls muted loop playsinline width="100%">
            <source src="https://jgkwak95.github.io/surfgan/assets/vid/vid7.mp4"
                    type="video/mp4">
          </video>
        </div>
      </div>

      <div class="column">
        <div class="columns is-centered">
          <div class="column content">
            <video id="vid6" autoplay controls muted loop playsinline width="100%">
              <source src="https://jgkwak95.github.io/surfgan/assets/vid/vid8.mp4"
                      type="video/mp4">
            </video> 
          </div>

        </div>
      </div>
    </div>
  </div>

  </div>

  </div>
  </div>
  </section>

<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    
    <h2 class="title">BibTeX</h2>  
    <pre><code>@inproceedings{kwak2022injecting,  
  title={Injecting 3D Perception of Controllable NeRF-GAN into StyleGAN for Editable Portrait Image Synthesis},  
  author={Kwak, Jeong-gi and Li, Yuanming and Yoon, Dongsik and Kim, Donghyeon and Han, David and Ko, Hanseok},  
  booktitle={European Conference on Computer Vision},  
  pages={236--253},  
  year={2022},  
  organization={Springer}  
}

  </div>
</section>

<footer class="footer">
  <div class="container">

    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p>
            The template of our project is borrowed from <a href="https://nerfies.github.io/">Nerfies</a>. Thanks to <a href="https://keunhong.com/">Keunhong Park</a> for sharing the template!
          </p>
        </div>
      </div>
    </div>
  </div>
</footer>

</body>
</html>
